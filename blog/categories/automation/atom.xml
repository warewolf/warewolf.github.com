<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: automation | Technical Generalism]]></title>
  <link href="http://warewolf.github.io/blog/categories/automation/atom.xml" rel="self"/>
  <link href="http://warewolf.github.io/"/>
  <updated>2013-05-02T21:40:22-04:00</updated>
  <id>http://warewolf.github.io/</id>
  <author>
    <name><![CDATA[Richard Harman]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Passwordless and secure SSH keys for log pulls]]></title>
    <link href="http://warewolf.github.io/blog/2013/04/29/passwordless-and-secure-ssh-keys-for-log-pulls/"/>
    <updated>2013-04-29T22:21:00-04:00</updated>
    <id>http://warewolf.github.io/blog/2013/04/29/passwordless-and-secure-ssh-keys-for-log-pulls</id>
    <content type="html"><![CDATA[<p>Secure passwordless SSH keys?  Surely some infosec policy auditor is crying right now.  Here's how to pacify them with a couple of options you may or may not have heard of in <code>~/.ssh/authorized_keys</code>.<!-- more --></p>

<p>So you want to set up a cron job to pull logs from LOGHOST.example.com to ANALYSISHOST.example.com.  I do it, beacuse then I have a local copy of the logs for me and my analysis team to work with.  Plus, it <strong>really</strong> helps to have your own copy of the logs when the remote syslog server box goes down in a network outage.</p>

<p>Most often the <em>Incident Response</em> team is just a consumer of audit data, not a producer.  Usually it's a <em>Server Operations</em> or <em>Network Operations</em> team that produces and collects the logs.  Since these are most likely audit logs of some kind, and could contain "sensitive" data, you should try to encrypt the data in flight.  My personal preference is <code>rsync</code> over <code>ssh</code>.  Rsync does the incremental file transfer mojo, and SSH does the encryption.</p>

<p>``` sh using rsync to pull logs from LOGHOST to ANALYSISHOST
[user@analysishost ~]$ rsync -Pav -e ssh \</p>

<pre><code>reader@loghost.example.com:/logs/firewall \
/store/firewall
</code></pre>

<p>```</p>

<p>This connects from analysishost to loghost with the user account "reader".  It pulls logs from /logs/firewall and drops them into /store/firewall.  It's basically <code>rsync source destination</code>.  Unless you're using <code>ssh-agent</code>, this will prompt you for a password every time -- which sucks for automation.  It does afford us two very important things though: It's a good exercise in testing that the rsync command works the way you want, and syncing over the backlog of logs the first time though.</p>
]]></content>
  </entry>
  
</feed>
